\hypertarget{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent}{}\doxysection{GW\+::S\+Y\+S\+T\+EM\+::G\+Concurrent Class Reference}
\label{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent}\index{GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}}
Inheritance diagram for GW\+::S\+Y\+S\+T\+EM\+::G\+Concurrent\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.000000cm]{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent}
\end{center}
\end{figure}
\doxysubsection*{Classes}
\begin{DoxyCompactItemize}
\item 
struct \mbox{\hyperlink{struct_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_1_1_e_v_e_n_t___d_a_t_a}{E\+V\+E\+N\+T\+\_\+\+D\+A\+TA}}
\end{DoxyCompactItemize}
\doxysubsection*{Public Types}
\begin{DoxyCompactItemize}
\item 
enum \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410}{Events}} \{ \newline
\mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410a74124942fd510cf90e28272d350c6edf}{Events\+::\+S\+I\+N\+G\+U\+L\+A\+R\+\_\+\+T\+A\+S\+K\+\_\+\+C\+O\+M\+P\+L\+E\+TE}}, 
\newline
\mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410a3d906f3d0203999feb03f63a3bae141f}{Events\+::\+P\+A\+R\+A\+L\+L\+E\+L\+\_\+\+T\+A\+S\+K\+\_\+\+C\+O\+M\+P\+L\+E\+TE}}, 
\newline
\mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410aaf8823b98f8294fe38dc0269f1739e02}{Events\+::\+P\+A\+R\+A\+L\+L\+E\+L\+\_\+\+S\+E\+C\+T\+I\+O\+N\+\_\+\+C\+O\+M\+P\+L\+E\+TE}}
 \}
\end{DoxyCompactItemize}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{group___g_return_values_gaf46a07bcad99edbe1e92a9fc99078617}{G\+Return}} \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a95b51643e43ae3887756fa3b52778dd3}{Create}} (bool \+\_\+suppress\+Events)
\item 
virtual \mbox{\hyperlink{group___g_return_values_gaf46a07bcad99edbe1e92a9fc99078617}{G\+Return}} \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a8ea5327583a9230f98ed9dab75ad1e53}{Branch\+Singular}} (std\+::function$<$ void()$>$ \+\_\+single\+Task)=0
\item 
virtual \mbox{\hyperlink{group___g_return_values_gaf46a07bcad99edbe1e92a9fc99078617}{G\+Return}} \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a54ad40d8eab6e546165f7c9901f13bfd}{Branch\+Dynamic}} (\mbox{\hyperlink{class_g_w_1_1_c_o_r_e_1_1_g_logic}{C\+O\+R\+E\+::\+G\+Logic}} \+\_\+dynamic\+Task)=0
\item 
{\footnotesize template$<$typename Input , typename Output $>$ }\\\mbox{\hyperlink{group___g_return_values_gaf46a07bcad99edbe1e92a9fc99078617}{G\+Return}} \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_aab999ec0f84199836c2168856ef8d3ec}{Branch\+Parallel}} (void($\ast$\+\_\+parallel\+Task)(const Input $\ast$, Output $\ast$, unsigned int, const void $\ast$), unsigned int \+\_\+max\+Section, unsigned int \+\_\+array\+Size, const void $\ast$\+\_\+user\+Data, int \+\_\+in\+Stride, const Input $\ast$\+\_\+input\+Array, int \+\_\+out\+Stride, Output $\ast$\+\_\+output\+Array)
\item 
virtual \mbox{\hyperlink{group___g_return_values_gaf46a07bcad99edbe1e92a9fc99078617}{G\+Return}} \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a340ed0d2d4ae20e84d47741314181851}{Converge}} (unsigned int \+\_\+spin\+Until)=0
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent}{G\+Concurrent}} is used by end users and even Gateware itself to launch one-\/time parallel thread work. Even though you can create multiple instances of a \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent}{G\+Concurrent}} they all utilize the same background thread pool. \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent}{G\+Concurrent}} is capable of branching flexible single tasks or even optimized mass parallel array workloads. 

Definition at line 65 of file G\+Concurrent.\+h.



\doxysubsection{Member Enumeration Documentation}
\mbox{\Hypertarget{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410}\label{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410}} 
\index{GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}!Events@{Events}}
\index{Events@{Events}!GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}}
\doxysubsubsection{\texorpdfstring{Events}{Events}}
{\footnotesize\ttfamily enum \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410}{G\+W\+::\+S\+Y\+S\+T\+E\+M\+::\+G\+Concurrent\+::\+Events}}\hspace{0.3cm}{\ttfamily [strong]}}



Events generated by \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent}{G\+Concurrent}}. These messages are used to notify observers when tasks complete. 

\begin{DoxyEnumFields}{Enumerator}
\raisebox{\heightof{T}}[0pt][0pt]{\index{SINGULAR\_TASK\_COMPLETE@{SINGULAR\_TASK\_COMPLETE}!GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}}\index{GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}!SINGULAR\_TASK\_COMPLETE@{SINGULAR\_TASK\_COMPLETE}}}\mbox{\Hypertarget{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410a74124942fd510cf90e28272d350c6edf}\label{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410a74124942fd510cf90e28272d350c6edf}} 
S\+I\+N\+G\+U\+L\+A\+R\+\_\+\+T\+A\+S\+K\+\_\+\+C\+O\+M\+P\+L\+E\+TE&A task started by \char`\"{}\+Branch\+Singular\char`\"{} has finished. \\
\hline

\raisebox{\heightof{T}}[0pt][0pt]{\index{PARALLEL\_TASK\_COMPLETE@{PARALLEL\_TASK\_COMPLETE}!GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}}\index{GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}!PARALLEL\_TASK\_COMPLETE@{PARALLEL\_TASK\_COMPLETE}}}\mbox{\Hypertarget{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410a3d906f3d0203999feb03f63a3bae141f}\label{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410a3d906f3d0203999feb03f63a3bae141f}} 
P\+A\+R\+A\+L\+L\+E\+L\+\_\+\+T\+A\+S\+K\+\_\+\+C\+O\+M\+P\+L\+E\+TE&A task started by \char`\"{}\+Branch\+Parallel\char`\"{} has finished. \\
\hline

\raisebox{\heightof{T}}[0pt][0pt]{\index{PARALLEL\_SECTION\_COMPLETE@{PARALLEL\_SECTION\_COMPLETE}!GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}}\index{GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}!PARALLEL\_SECTION\_COMPLETE@{PARALLEL\_SECTION\_COMPLETE}}}\mbox{\Hypertarget{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410aaf8823b98f8294fe38dc0269f1739e02}\label{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410aaf8823b98f8294fe38dc0269f1739e02}} 
P\+A\+R\+A\+L\+L\+E\+L\+\_\+\+S\+E\+C\+T\+I\+O\+N\+\_\+\+C\+O\+M\+P\+L\+E\+TE&A specific sub-\/section of a parallel task has finished. \\
\hline

\end{DoxyEnumFields}


Definition at line 94 of file G\+Concurrent.\+h.



\doxysubsection{Member Function Documentation}
\mbox{\Hypertarget{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a95b51643e43ae3887756fa3b52778dd3}\label{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a95b51643e43ae3887756fa3b52778dd3}} 
\index{GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}!Create@{Create}}
\index{Create@{Create}!GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}}
\doxysubsubsection{\texorpdfstring{Create()}{Create()}}
{\footnotesize\ttfamily \mbox{\hyperlink{group___g_return_values_gaf46a07bcad99edbe1e92a9fc99078617}{G\+Return}} G\+W\+::\+S\+Y\+S\+T\+E\+M\+::\+G\+Concurrent\+::\+Create (\begin{DoxyParamCaption}\item[{bool}]{\+\_\+suppress\+Events }\end{DoxyParamCaption})}



Allocates \& Initializes a \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent}{G\+Concurrent}}. 

Creates a \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent}{G\+Concurrent}} proxy which enables you to launch operations on other threads and synchronize with them. The \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent}{G\+Concurrent}} is a straightforward way to add tasks to Gateware\textquotesingle{}s internal threadpool.


\begin{DoxyParams}[1]{Parameters}
\mbox{\texttt{ in}}  & {\em \+\_\+suppress\+Events} & If you only use \char`\"{}\+Converge\char`\"{} or do not require \mbox{\hyperlink{struct_g_w_1_1_g_event}{G\+Event}} notifications, set to false for better perfomance.\\
\hline
\end{DoxyParams}

\begin{DoxyRetVals}{Return values}
{\em \mbox{\hyperlink{group___g_return_values_ggaf46a07bcad99edbe1e92a9fc99078617ad0749aaba8b833466dfcbb0428e4f89c}{G\+Return\+::\+S\+U\+C\+C\+E\+SS}}} & \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent}{G\+Concurrent}} created successfully, ready to branch work. \\
\hline
\end{DoxyRetVals}
\mbox{\Hypertarget{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a8ea5327583a9230f98ed9dab75ad1e53}\label{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a8ea5327583a9230f98ed9dab75ad1e53}} 
\index{GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}!BranchSingular@{BranchSingular}}
\index{BranchSingular@{BranchSingular}!GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}}
\doxysubsubsection{\texorpdfstring{BranchSingular()}{BranchSingular()}}
{\footnotesize\ttfamily virtual \mbox{\hyperlink{group___g_return_values_gaf46a07bcad99edbe1e92a9fc99078617}{G\+Return}} G\+W\+::\+S\+Y\+S\+T\+E\+M\+::\+G\+Concurrent\+::\+Branch\+Singular (\begin{DoxyParamCaption}\item[{std\+::function$<$ void()$>$}]{\+\_\+single\+Task }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [pure virtual]}}



Launch a single-\/thread operation to run concurrently with this thread. 

Adds a job to Gateware\textquotesingle{}s internal threadpool, wait for this operation using \char`\"{}\+Converge\char`\"{} or listen for\+: \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410a74124942fd510cf90e28272d350c6edf}{Events\+::\+S\+I\+N\+G\+U\+L\+A\+R\+\_\+\+T\+A\+S\+K\+\_\+\+C\+O\+M\+P\+L\+E\+TE}}


\begin{DoxyParams}[1]{Parameters}
\mbox{\texttt{ in}}  & {\em \+\_\+single\+Task} & Any function/lambda that has a void return type.\\
\hline
\end{DoxyParams}

\begin{DoxyRetVals}{Return values}
{\em \mbox{\hyperlink{group___g_return_values_ggaf46a07bcad99edbe1e92a9fc99078617af295a0c3e37c94f078e1c5476479132d}{G\+Return\+::\+I\+N\+V\+A\+L\+I\+D\+\_\+\+A\+R\+G\+U\+M\+E\+NT}}} & You must provide a non-\/null function to execute. \\
\hline
{\em \mbox{\hyperlink{group___g_return_values_ggaf46a07bcad99edbe1e92a9fc99078617ad0749aaba8b833466dfcbb0428e4f89c}{G\+Return\+::\+S\+U\+C\+C\+E\+SS}}} & We have successfully submitted the task for processing. \\
\hline
\end{DoxyRetVals}
\mbox{\Hypertarget{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a54ad40d8eab6e546165f7c9901f13bfd}\label{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a54ad40d8eab6e546165f7c9901f13bfd}} 
\index{GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}!BranchDynamic@{BranchDynamic}}
\index{BranchDynamic@{BranchDynamic}!GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}}
\doxysubsubsection{\texorpdfstring{BranchDynamic()}{BranchDynamic()}}
{\footnotesize\ttfamily virtual \mbox{\hyperlink{group___g_return_values_gaf46a07bcad99edbe1e92a9fc99078617}{G\+Return}} G\+W\+::\+S\+Y\+S\+T\+E\+M\+::\+G\+Concurrent\+::\+Branch\+Dynamic (\begin{DoxyParamCaption}\item[{\mbox{\hyperlink{class_g_w_1_1_c_o_r_e_1_1_g_logic}{C\+O\+R\+E\+::\+G\+Logic}}}]{\+\_\+dynamic\+Task }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [pure virtual]}}



Launch a flexible and safe single-\/thread operation to run concurrently with this thread. 

Adds a job to Gateware\textquotesingle{}s internal threadpool, wait for this operation using \char`\"{}\+Converge\char`\"{} or listen for\+: \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410a74124942fd510cf90e28272d350c6edf}{Events\+::\+S\+I\+N\+G\+U\+L\+A\+R\+\_\+\+T\+A\+S\+K\+\_\+\+C\+O\+M\+P\+L\+E\+TE}}


\begin{DoxyParams}[1]{Parameters}
\mbox{\texttt{ in}}  & {\em \+\_\+dynamic\+Task} & A valid G\+Logic proxy for safe/interchanagable execution.\\
\hline
\end{DoxyParams}

\begin{DoxyRetVals}{Return values}
{\em \mbox{\hyperlink{group___g_return_values_ggaf46a07bcad99edbe1e92a9fc99078617af295a0c3e37c94f078e1c5476479132d}{G\+Return\+::\+I\+N\+V\+A\+L\+I\+D\+\_\+\+A\+R\+G\+U\+M\+E\+NT}}} & You must provide a non-\/invalid G\+Logic proxy to reference. \\
\hline
{\em \mbox{\hyperlink{group___g_return_values_ggaf46a07bcad99edbe1e92a9fc99078617ad0749aaba8b833466dfcbb0428e4f89c}{G\+Return\+::\+S\+U\+C\+C\+E\+SS}}} & We have successfully submitted the task for processing. \\
\hline
\end{DoxyRetVals}
\mbox{\Hypertarget{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_aab999ec0f84199836c2168856ef8d3ec}\label{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_aab999ec0f84199836c2168856ef8d3ec}} 
\index{GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}!BranchParallel@{BranchParallel}}
\index{BranchParallel@{BranchParallel}!GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}}
\doxysubsubsection{\texorpdfstring{BranchParallel()}{BranchParallel()}}
{\footnotesize\ttfamily template$<$typename Input , typename Output $>$ \\
\mbox{\hyperlink{group___g_return_values_gaf46a07bcad99edbe1e92a9fc99078617}{G\+Return}} G\+W\+::\+S\+Y\+S\+T\+E\+M\+::\+G\+Concurrent\+::\+Branch\+Parallel (\begin{DoxyParamCaption}\item[{void($\ast$)(const Input $\ast$, Output $\ast$, unsigned int, const void $\ast$)}]{\+\_\+parallel\+Task,  }\item[{unsigned int}]{\+\_\+max\+Section,  }\item[{unsigned int}]{\+\_\+array\+Size,  }\item[{const void $\ast$}]{\+\_\+user\+Data,  }\item[{int}]{\+\_\+in\+Stride,  }\item[{const Input $\ast$}]{\+\_\+input\+Array,  }\item[{int}]{\+\_\+out\+Stride,  }\item[{Output $\ast$}]{\+\_\+output\+Array }\end{DoxyParamCaption})}



Launch a multi-\/thread spanning simulatenous array modification operation to run concurrently with this thread. 

Allows you to process large contigious data sets using a divide \& conquer approach. Based on how many \char`\"{}\+\_\+max\+Sections\char`\"{} are required to traverse \char`\"{}\+\_\+array\+Size\char`\"{} we create that many jobs in the internal thread pool. Then each job will run \char`\"{}\+\_\+parallel\+Task\char`\"{} for each input/output pair in it\textquotesingle{}s designated section (optional array location is provided). To know when a single section completes listen for \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410aaf8823b98f8294fe38dc0269f1739e02}{Events\+::\+P\+A\+R\+A\+L\+L\+E\+L\+\_\+\+S\+E\+C\+T\+I\+O\+N\+\_\+\+C\+O\+M\+P\+L\+E\+TE}}. There is no cross section ordering garuntee. Global resources accessed by the provided operation are your responsibility to synchronize for thread safety (recc\+: G\+Thread\+Shared). However the provided arrays are safely accessed due to being divided evenly amongst the internal jobs (no overlap). You may wait for this entire operation to complete using \char`\"{}\+Converge\char`\"{} or listen for \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a9402fcf08b745b49b7ac315749b49410a3d906f3d0203999feb03f63a3bae141f}{Events\+::\+P\+A\+R\+A\+L\+L\+E\+L\+\_\+\+T\+A\+S\+K\+\_\+\+C\+O\+M\+P\+L\+E\+TE}} Once you have \char`\"{}\+Converged\char`\"{} or received the appropriate message(s) you are safe to acd amongst processing cores.


\begin{DoxyParams}[1]{Parameters}
\mbox{\texttt{ in}}  & {\em \+\_\+parallel\+Task} & Pointer to static operation responsible for element processing, called once for each specific element. \\
\hline
\mbox{\texttt{ in}}  & {\em \+\_\+max\+Section} & The maximum \# of elements processed by a thread at once, this has the largest impact on perfomance. N\+O\+TE\+: As rule of thumb this value should be smaller for complex operations and larger for simplistic ones. \\
\hline
\mbox{\texttt{ in}}  & {\em \+\_\+array\+Size} & The size of array or problem domain that is to be divideey wish each routine to have access to. \\
\hline
\mbox{\texttt{ in}}  & {\em \+\_\+user\+Data} & (O\+P\+T\+I\+O\+N\+AL) Pointer to some custom user provided data that the input/output data arrays might need. \\
\hline
\mbox{\texttt{ in}}  & {\em \+\_\+in\+Stride} & (O\+P\+T\+I\+O\+N\+AL) if 0 then sizeof(\+Input) type used for input array traversal, otherwise this byte amount is used. \\
\hline
\mbox{\texttt{ in}}  & {\em \+\_\+input\+Array} & (O\+P\+T\+I\+O\+N\+AL) Array of input data elements that will be fed to the processing system. \\
\hline
\mbox{\texttt{ in}}  & {\em \+\_\+out\+Stride} & (O\+P\+T\+I\+O\+N\+AL) if 0 then sizeof(\+Output) type used for output array traversal, otherwise this byte amount is used. \\
\hline
\mbox{\texttt{ out}}  & {\em \+\_\+output\+Array} & (O\+P\+T\+I\+O\+N\+AL) Array of output data elements that will be fed to the processing system.\\
\hline
\end{DoxyParams}

\begin{DoxyRetVals}{Return values}
{\em \mbox{\hyperlink{group___g_return_values_ggaf46a07bcad99edbe1e92a9fc99078617a46798451fc1bd08482d7c01fc84109a6}{G\+Return\+::\+M\+E\+M\+O\+R\+Y\+\_\+\+C\+O\+R\+R\+U\+P\+T\+I\+ON}}} & \+\_\+input\+Array \& \+\_\+output\+Array have an overlapping memory space. (Just use \+\_\+output\+Array instead) \\
\hline
{\em \mbox{\hyperlink{group___g_return_values_ggaf46a07bcad99edbe1e92a9fc99078617af295a0c3e37c94f078e1c5476479132d}{G\+Return\+::\+I\+N\+V\+A\+L\+I\+D\+\_\+\+A\+R\+G\+U\+M\+E\+NT}}} & You must provide a non-\/null function to execute and a non-\/zero array\+Size \& max\+Section. Cannot use the same array for \+\_\+input\+Array and \+\_\+output\+Array. In this situation, just use \+\_\+output\+Array. \\
\hline
{\em \mbox{\hyperlink{group___g_return_values_ggaf46a07bcad99edbe1e92a9fc99078617ad0749aaba8b833466dfcbb0428e4f89c}{G\+Return\+::\+S\+U\+C\+C\+E\+SS}}} & We have successfully submitted the task for processing. \\
\hline
\end{DoxyRetVals}
\mbox{\Hypertarget{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a340ed0d2d4ae20e84d47741314181851}\label{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent_a340ed0d2d4ae20e84d47741314181851}} 
\index{GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}!Converge@{Converge}}
\index{Converge@{Converge}!GW::SYSTEM::GConcurrent@{GW::SYSTEM::GConcurrent}}
\doxysubsubsection{\texorpdfstring{Converge()}{Converge()}}
{\footnotesize\ttfamily virtual \mbox{\hyperlink{group___g_return_values_gaf46a07bcad99edbe1e92a9fc99078617}{G\+Return}} G\+W\+::\+S\+Y\+S\+T\+E\+M\+::\+G\+Concurrent\+::\+Converge (\begin{DoxyParamCaption}\item[{unsigned int}]{\+\_\+spin\+Until }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [pure virtual]}}



Forces the current thread to wait until any \& all branched processing has completed. 

Polls the \mbox{\hyperlink{class_g_w_1_1_s_y_s_t_e_m_1_1_g_concurrent}{G\+Concurrent}} until all running tasks have completed. Use this when you need to access resources on the current thread that may still be processing elsewhere. If you want a less invasive method of waiting and responding, consider using the built-\/in messaging system to be notified instead.


\begin{DoxyParams}[1]{Parameters}
\mbox{\texttt{ in}}  & {\em \+\_\+spin\+Until} & Determine how long the current thread will spinlock waiting for all Tasks to complete. (in N\+A\+N\+O\+S\+E\+C\+O\+N\+DS) Once \char`\"{}\+\_\+spin\+Until\char`\"{} nanoseconds has elapsed the current thread will yield to the OS scheduler. (1 millisecond yield) Upon being re-\/scheduled the thread will try to spinlock again until \char`\"{}\+\_\+spin\+Until\char`\"{} is reached again or completion. N\+O\+TE\+: If your not in a time/performance critical area you should just use 0. Wake times dependent on OS resolution.\\
\hline
\end{DoxyParams}

\begin{DoxyRetVals}{Return values}
{\em \mbox{\hyperlink{group___g_return_values_ggaf46a07bcad99edbe1e92a9fc99078617a36fc6065a3e970bc3e6b2e59da52bf2a}{G\+Return\+::\+F\+A\+I\+L\+U\+RE}}} & There have been no Tasks ever or since you last Converged. \\
\hline
{\em \mbox{\hyperlink{group___g_return_values_ggaf46a07bcad99edbe1e92a9fc99078617ad0749aaba8b833466dfcbb0428e4f89c}{G\+Return\+::\+S\+U\+C\+C\+E\+SS}}} & Tasks were running and we sucessfully waited for their completion. \\
\hline
\end{DoxyRetVals}
